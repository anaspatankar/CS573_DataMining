{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#sklearn test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# transform data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#Imputation and normalization\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"feature_set_1.csv\")\n",
    "df_2 = pd.read_csv(\"feature_set_2.csv\")\n",
    "df_3 = pd.read_csv(\"feature_set_3.csv\")\n",
    "df_1 = df_1.drop(columns=['Unnamed: 0', 'SK_ID_CURR'])\n",
    "df_2 = df_2.drop(columns=['Unnamed: 0', 'SK_ID_CURR'])\n",
    "df_3 = df_3.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234387 19683 Ratio: 0.08397650040317936\n"
     ]
    }
   ],
   "source": [
    "Negatives = df['TARGET'][df['TARGET']==0].count()\n",
    "Positives = df['TARGET'][df['TARGET']==1].count()\n",
    "print(Negatives, Positives, \"Ratio:\", Positives/Negatives)\n",
    "Pos = df[df['TARGET']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling Dataset to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = df[df.TARGET == 0].sample(n=Positives).index\n",
    "Neg = df.iloc[random_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sampled_set = pd.concat([Pos,Neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['TARGET']\n",
    "X = df.drop(['TARGET'], axis = 1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=0)\n",
    "\n",
    "Y_sampled = under_sampled_set['TARGET']\n",
    "X_sampled = under_sampled_set.drop(['TARGET'], axis = 1)\n",
    "\n",
    "X_train_sampled, X_test_sampled, Y_train_sampled, Y_test_sampled = train_test_split(X_sampled,Y_sampled, test_size=0.3, random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[254069])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NAs\n",
    "rem = 0\n",
    "for i in range(len(df['ORGANIZATION_TYPE_Insurance'])):\n",
    "    y = df['ORGANIZATION_TYPE_Insurance'].iloc[i]\n",
    "    if pd.isna(y)!=False:\n",
    "        print(i)\n",
    "        rem = i\n",
    "df = df.drop(df.index[rem])\n",
    "#Y_test = Y_test.drop(Y_test.index[rem])\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import machine learning algorithms\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[9934 3869]\n",
      " [4280 9473]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.72      0.71     13803\n",
      "        1.0       0.71      0.69      0.70     13753\n",
      "\n",
      "avg / total       0.70      0.70      0.70     27556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=100, random_state = 0)\n",
    "gb.fit(X_train_sampled, Y_train_sampled)\n",
    "predictions = gb.predict(X_train_sampled)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_train_sampled, predictions))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(Y_train_sampled, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve = 0.75\n"
     ]
    }
   ],
   "source": [
    "Y_scores = gb.decision_function(X_test_sampled)\n",
    "fpr_gb, tpr_gb, _ = roc_curve(Y_test_sampled, Y_scores)\n",
    "roc_auc_gb = auc(fpr_gb, tpr_gb)\n",
    "\n",
    "print(\"Area under ROC curve = {:0.2f}\".format(roc_auc_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7042749310494992"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_train_sampled,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7100134912307"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Y_train_sampled,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.688795171962481"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_train_sampled,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[114912  49165]\n",
      " [  4357   9415]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.70      0.81    164077\n",
      "        1.0       0.16      0.68      0.26     13772\n",
      "\n",
      "avg / total       0.90      0.70      0.77    177849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_2 = gb.predict(X_train)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_train, predictions_2))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(Y_train, predictions_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6990593143621836"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_train,predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16072038238306588"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(Y_train,predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6836334591925646"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(Y_train,predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = confusion_matrix(Y_train, predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = c[0][0]\n",
    "FP = c[0][1]\n",
    "FN = c[1][0]\n",
    "TP = c[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE LOOP FOR DIFFERENT SAMPLING RATIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(data,ratio):\n",
    "    df = data\n",
    "    Pos = df[df['TARGET']==1]\n",
    "    Neg = df[df['TARGET']==0]\n",
    "    N = round((len(Pos)*ratio))\n",
    "    random_samples = Neg.sample(n=N).index\n",
    "    Neg = df.iloc[random_samples]\n",
    "    sampled_set = pd.concat([Pos,Neg])\n",
    "    return(sampled_set)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(data,ratio,test_size):\n",
    "    df = data\n",
    "    df_s = sampling(df,ratio)\n",
    "    Y = df['TARGET']\n",
    "    X = df.drop(['TARGET'], axis = 1)\n",
    "    Ys = df_s['TARGET']\n",
    "    Xs = df_s.drop(['TARGET'], axis = 1)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=0)\n",
    "    Xs_train, Xs_test, Ys_train, Ys_test = train_test_split(Xs,Ys, test_size=test_size, random_state=0)\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, random_state = 0)\n",
    "    gb.fit(Xs_train, Ys_train)\n",
    "    predictions = gb.predict(X_train)\n",
    "    c = confusion_matrix(Y_train, predictions)\n",
    "    TN = c[0][0]\n",
    "    print(\"True Negatives:\",TN)\n",
    "    FP = c[0][1]\n",
    "    print(\"False Positives:\",FP)\n",
    "    FN = c[1][0]\n",
    "    print(\"False Negatives:\",FN)\n",
    "    TP = c[1][1]\n",
    "    print(\"True Positives:\",TP)\n",
    "    #Y_scores = gb.decision_function(X_test_sampled)\n",
    "    #fpr_gb, tpr_gb, _ = roc_curve(Y_test_sampled, Y_scores)\n",
    "    #roc_auc_gb = auc(fpr_gb, tpr_gb)\n",
    "    acc = accuracy_score(Y_train,predictions)\n",
    "    precision = precision_score(Y_train,predictions)\n",
    "    recall = recall_score(Y_train,predictions)\n",
    "    f1 = f1_score(T_t)\n",
    "    return(acc,precision,recall,f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio:  4\n",
      "True Negatives: 187486\n",
      "False Positives: 78\n",
      "False Negatives: 15608\n",
      "True Positives: 82\n"
     ]
    }
   ],
   "source": [
    "R = [0.5,0.8,1,1.2,1.5,2,4]\n",
    "\n",
    "\n",
    "for ratio in R:\n",
    "    print(\"Ratio: \",ratio)\n",
    "    a,p,r = gradient_boosting(df,ratio,0.2)\n",
    "    accs.append(a)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "\n",
    "output_file(\"line.html\")\n",
    "\n",
    "p = figure(plot_width=400, plot_height=400)\n",
    "\n",
    "# add a line renderer\n",
    "p.line(R[:7], accs[:7], line_width=2, color='blue', legend='accuracy')\n",
    "p.line(R[:7], precisions[:7], line_width=2, color='green', legend='precision')\n",
    "p.line(R[:7], recalls[:7], line_width=2, color='red', legend='recall')\n",
    "p.legend.location = \"center_right\"\n",
    "p.xaxis.axis_label = 'Negative to Positive Sampling Ratio'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting R = 1. Recall takes priority over everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(data,gb):\n",
    "    df = data\n",
    "    df_s = sampling(df,1)\n",
    "    Y = df['TARGET']\n",
    "    X = df.drop(['TARGET'], axis = 1)\n",
    "    Ys = df_s['TARGET']\n",
    "    Xs = df_s.drop(['TARGET'], axis = 1)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=0)\n",
    "    Xs_train, Xs_test, Ys_train, Ys_test = train_test_split(Xs,Ys, test_size=0.3, random_state=0)\n",
    "    #gb = GradientBoostingClassifier(n_estimators=100, random_state = 0)\n",
    "    #Unsampled Training\n",
    "    gb.fit(X_train, Y_train)\n",
    "    print('Checkpoint')\n",
    "    predictions = gb.predict(X_train)\n",
    "    acc = accuracy_score(Y_train,predictions)\n",
    "    precision = precision_score(Y_train,predictions)\n",
    "    recall = recall_score(Y_train,predictions)\n",
    "    f1 = f1_score(Y_train,predictions)\n",
    "    print(\"Unsampled Train accuracy:\",acc)\n",
    "    print(\"Unsampled Train  precision:\",precision)\n",
    "    print(\"Unsampled Train recall:\",recall)\n",
    "    print(\"Unsampled Train f1:\",f1)\n",
    "    #Unsampled Test\n",
    "    predictions = gb.predict(X_test)\n",
    "    acc = accuracy_score(Y_test,predictions)\n",
    "    precision = precision_score(Y_test,predictions)\n",
    "    recall = recall_score(Y_test,predictions)\n",
    "    f1 = f1_score(Y_test,predictions)\n",
    "    print(\"Unsampled Test accuracy:\",acc)\n",
    "    print(\"Unsampled Test precision:\",precision)\n",
    "    print(\"Unsampled Test recall:\",recall)\n",
    "    print(\"Unsampled Test f1:\",f1)\n",
    "    #Sampled Training\n",
    "    gb.fit(Xs_train, Ys_train)\n",
    "    predictions = gb.predict(X_train)\n",
    "    acc = accuracy_score(Y_train,predictions)\n",
    "    precision = precision_score(Y_train,predictions)\n",
    "    recall = recall_score(Y_train,predictions)\n",
    "    f1 = f1_score(Y_train,predictions)\n",
    "    print(\"Sampled Train accuracy:\",acc)\n",
    "    print(\"Sampled Train precision:\",precision)\n",
    "    print(\"Sampled Train recall:\",recall)\n",
    "    print(\"Sampled Train f1:\",f1)\n",
    "    #Sampled Test\n",
    "    predictions = gb.predict(X_test)\n",
    "    acc = accuracy_score(Y_test,predictions)\n",
    "    precision = precision_score(Y_test,predictions)\n",
    "    recall = recall_score(Y_test,predictions)\n",
    "    f1 = f1_score(Y_test,predictions)\n",
    "    print(\"Sampled Test accuracy:\",acc)\n",
    "    print(\"Sampled Test precision:\",precision)\n",
    "    print(\"Sampled Test recall:\",recall)\n",
    "    print(\"Sampled Test f1:\",f1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint\n",
      "Unsampled Train accuracy: 0.9218654910177138\n",
      "Unsampled Train  precision: 0.8153409090909091\n",
      "Unsampled Train recall: 0.04924220760651987\n",
      "Unsampled Train f1: 0.09287524944717114\n",
      "Unsampled Test accuracy: 0.9201335443449606\n",
      "Unsampled Test precision: 0.4606741573033708\n",
      "Unsampled Test recall: 0.0223433242506812\n",
      "Unsampled Test f1: 0.04261954261954262\n",
      "Sampled Train accuracy: 0.6932364568864194\n",
      "Sampled Train precision: 0.17058408424709587\n",
      "Sampled Train recall: 0.7189019159279383\n",
      "Sampled Train f1: 0.27573952814978114\n",
      "Sampled Test accuracy: 0.6944414334337806\n",
      "Sampled Test precision: 0.16947271631947747\n",
      "Sampled Test recall: 0.7282016348773842\n",
      "Sampled Test f1: 0.2749556315748862\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state = 0,n_estimators=150, max_depth = 5)\n",
    "scoring(df_1,gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint\n",
      "Unsampled Train accuracy: 0.9222975327167061\n",
      "Unsampled Train  precision: 0.8868501529051988\n",
      "Unsampled Train recall: 0.04975693451529883\n",
      "Unsampled Train f1: 0.09422722841979855\n",
      "Unsampled Test accuracy: 0.9201769028985193\n",
      "Unsampled Test precision: 0.4642857142857143\n",
      "Unsampled Test recall: 0.02125340599455041\n",
      "Unsampled Test f1: 0.04064616988014591\n",
      "Sampled Train accuracy: 0.693845031752742\n",
      "Sampled Train precision: 0.17178920538510556\n",
      "Sampled Train recall: 0.7246782956820131\n",
      "Sampled Train f1: 0.27773881022313796\n",
      "Sampled Test accuracy: 0.6949942549916535\n",
      "Sampled Test precision: 0.17039619651347068\n",
      "Sampled Test recall: 0.732425068119891\n",
      "Sampled Test f1: 0.2764721007971201\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state = 0,n_estimators=150, max_depth = 5)\n",
    "scoring(df_2,gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint\n",
      "Unsampled Train accuracy: 0.9228782339250291\n",
      "Unsampled Train  precision: 0.827893175074184\n",
      "Unsampled Train recall: 0.06382613668859022\n",
      "Unsampled Train f1: 0.11851537195348591\n",
      "Unsampled Test accuracy: 0.9200034686842847\n",
      "Unsampled Test precision: 0.4574468085106383\n",
      "Unsampled Test recall: 0.029291553133514985\n",
      "Unsampled Test f1: 0.05505761843790013\n",
      "Sampled Train accuracy: 0.7004464430889588\n",
      "Sampled Train precision: 0.1764965031114048\n",
      "Sampled Train recall: 0.7331998856162425\n",
      "Sampled Train f1: 0.2845063858590118\n",
      "Sampled Test accuracy: 0.7009452164675787\n",
      "Sampled Test precision: 0.1747357599511678\n",
      "Sampled Test recall: 0.741008174386921\n",
      "Sampled Test f1: 0.28278784412613406\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state = 0,n_estimators=150, max_depth = 5)\n",
    "scoring(df_3,gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
