{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('feature_set_1.csv')\n",
    "X = dataset.iloc[:, 3:].values\n",
    "y = dataset.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34970/34970 [==============================] - 5s 140us/step - loss: 0.6125 - acc: 0.6677\n",
      "Epoch 2/100\n",
      "34970/34970 [==============================] - 5s 148us/step - loss: 0.5982 - acc: 0.6797\n",
      "Epoch 3/100\n",
      "34970/34970 [==============================] - 5s 151us/step - loss: 0.5917 - acc: 0.6862\n",
      "Epoch 4/100\n",
      "34970/34970 [==============================] - 5s 140us/step - loss: 0.5832 - acc: 0.6926\n",
      "Epoch 5/100\n",
      "34970/34970 [==============================] - 5s 145us/step - loss: 0.5734 - acc: 0.7012\n",
      "Epoch 6/100\n",
      "34970/34970 [==============================] - 5s 140us/step - loss: 0.5605 - acc: 0.7073\n",
      "Epoch 7/100\n",
      "34970/34970 [==============================] - 5s 135us/step - loss: 0.5441 - acc: 0.7186\n",
      "Epoch 8/100\n",
      "34970/34970 [==============================] - 5s 134us/step - loss: 0.5271 - acc: 0.7242\n",
      "Epoch 9/100\n",
      "34970/34970 [==============================] - 5s 140us/step - loss: 0.5082 - acc: 0.7367\n",
      "Epoch 10/100\n",
      "34970/34970 [==============================] - 5s 151us/step - loss: 0.4889 - acc: 0.7491\n",
      "Epoch 11/100\n",
      "34970/34970 [==============================] - 5s 140us/step - loss: 0.4690 - acc: 0.7597\n",
      "Epoch 12/100\n",
      "34970/34970 [==============================] - 5s 145us/step - loss: 0.4511 - acc: 0.7709\n",
      "Epoch 13/100\n",
      "34970/34970 [==============================] - 5s 137us/step - loss: 0.4331 - acc: 0.7830\n",
      "Epoch 14/100\n",
      "34970/34970 [==============================] - 5s 137us/step - loss: 0.4153 - acc: 0.7924\n",
      "Epoch 15/100\n",
      "34970/34970 [==============================] - 5s 144us/step - loss: 0.3992 - acc: 0.8029\n",
      "Epoch 16/100\n",
      "34970/34970 [==============================] - 5s 133us/step - loss: 0.3823 - acc: 0.8115\n",
      "Epoch 17/100\n",
      "34970/34970 [==============================] - 5s 136us/step - loss: 0.3686 - acc: 0.8203\n",
      "Epoch 18/100\n",
      "34970/34970 [==============================] - 5s 134us/step - loss: 0.3522 - acc: 0.8303\n",
      "Epoch 19/100\n",
      "34970/34970 [==============================] - 5s 142us/step - loss: 0.3384 - acc: 0.8362\n",
      "Epoch 20/100\n",
      "34970/34970 [==============================] - 5s 150us/step - loss: 0.3239 - acc: 0.8456\n",
      "Epoch 21/100\n",
      "34970/34970 [==============================] - 5s 142us/step - loss: 0.3109 - acc: 0.8523\n",
      "Epoch 22/100\n",
      "34970/34970 [==============================] - 5s 143us/step - loss: 0.2984 - acc: 0.8587\n",
      "Epoch 23/100\n",
      "34970/34970 [==============================] - 5s 143us/step - loss: 0.2917 - acc: 0.8628\n",
      "Epoch 24/100\n",
      "34970/34970 [==============================] - 5s 138us/step - loss: 0.2771 - acc: 0.8692\n",
      "Epoch 25/100\n",
      "34970/34970 [==============================] - 5s 141us/step - loss: 0.2727 - acc: 0.8731\n",
      "Epoch 26/100\n",
      "34970/34970 [==============================] - 5s 135us/step - loss: 0.2623 - acc: 0.8798\n",
      "Epoch 27/100\n",
      "34970/34970 [==============================] - 5s 144us/step - loss: 0.2549 - acc: 0.8832\n",
      "Epoch 28/100\n",
      "34970/34970 [==============================] - 5s 140us/step - loss: 0.2431 - acc: 0.8894\n",
      "Epoch 29/100\n",
      "34970/34970 [==============================] - 5s 145us/step - loss: 0.2376 - acc: 0.8904\n",
      "Epoch 30/100\n",
      "34970/34970 [==============================] - 5s 141us/step - loss: 0.2321 - acc: 0.8943\n",
      "Epoch 31/100\n",
      "34970/34970 [==============================] - 5s 136us/step - loss: 0.2279 - acc: 0.8958\n",
      "Epoch 32/100\n",
      "34970/34970 [==============================] - 5s 144us/step - loss: 0.2186 - acc: 0.8995\n",
      "Epoch 33/100\n",
      "34970/34970 [==============================] - 5s 146us/step - loss: 0.2146 - acc: 0.9015\n",
      "Epoch 34/100\n",
      "34970/34970 [==============================] - 5s 143us/step - loss: 0.2061 - acc: 0.9075\n",
      "Epoch 35/100\n",
      "34970/34970 [==============================] - 5s 144us/step - loss: 0.2063 - acc: 0.9093\n",
      "Epoch 36/100\n",
      "34970/34970 [==============================] - 5s 141us/step - loss: 0.2023 - acc: 0.9106\n",
      "Epoch 37/100\n",
      "34970/34970 [==============================] - 5s 140us/step - loss: 0.1940 - acc: 0.9140\n",
      "Epoch 38/100\n",
      "34970/34970 [==============================] - 5s 145us/step - loss: 0.1949 - acc: 0.9137\n",
      "Epoch 39/100\n",
      "34970/34970 [==============================] - 5s 142us/step - loss: 0.1877 - acc: 0.9170\n",
      "Epoch 40/100\n",
      "34970/34970 [==============================] - 5s 144us/step - loss: 0.1798 - acc: 0.9198\n",
      "Epoch 41/100\n",
      "34970/34970 [==============================] - 5s 154us/step - loss: 0.1741 - acc: 0.9200\n",
      "Epoch 42/100\n",
      "34970/34970 [==============================] - 5s 147us/step - loss: 0.1784 - acc: 0.9211\n",
      "Epoch 43/100\n",
      "34970/34970 [==============================] - 5s 147us/step - loss: 0.1733 - acc: 0.9236\n",
      "Epoch 44/100\n",
      "34970/34970 [==============================] - 5s 147us/step - loss: 0.1668 - acc: 0.9273\n",
      "Epoch 45/100\n",
      "34970/34970 [==============================] - 5s 142us/step - loss: 0.1666 - acc: 0.9282\n",
      "Epoch 46/100\n",
      "34970/34970 [==============================] - 5s 133us/step - loss: 0.1642 - acc: 0.9285\n",
      "Epoch 47/100\n",
      "34970/34970 [==============================] - 5s 139us/step - loss: 0.1660 - acc: 0.9273\n",
      "Epoch 48/100\n",
      "34970/34970 [==============================] - 5s 143us/step - loss: 0.1578 - acc: 0.9306\n",
      "Epoch 49/100\n",
      "34970/34970 [==============================] - 5s 136us/step - loss: 0.1574 - acc: 0.9318\n",
      "Epoch 50/100\n",
      "34970/34970 [==============================] - 5s 134us/step - loss: 0.1530 - acc: 0.9343\n",
      "Epoch 51/100\n",
      "34970/34970 [==============================] - 5s 139us/step - loss: 0.1517 - acc: 0.9351\n",
      "Epoch 52/100\n",
      "34970/34970 [==============================] - 5s 136us/step - loss: 0.1475 - acc: 0.9358\n",
      "Epoch 53/100\n",
      "34970/34970 [==============================] - 5s 134us/step - loss: 0.1464 - acc: 0.9367\n",
      "Epoch 54/100\n",
      "34970/34970 [==============================] - 5s 139us/step - loss: 0.1428 - acc: 0.9373\n",
      "Epoch 55/100\n",
      "34970/34970 [==============================] - 5s 133us/step - loss: 0.1404 - acc: 0.9391\n",
      "Epoch 56/100\n",
      "34970/34970 [==============================] - 5s 139us/step - loss: 0.1427 - acc: 0.9398\n",
      "Epoch 57/100\n",
      "34970/34970 [==============================] - 5s 133us/step - loss: 0.1397 - acc: 0.9401\n",
      "Epoch 58/100\n",
      "34970/34970 [==============================] - 5s 139us/step - loss: 0.1339 - acc: 0.9424\n",
      "Epoch 59/100\n",
      "34970/34970 [==============================] - 5s 130us/step - loss: 0.1338 - acc: 0.9414\n",
      "Epoch 60/100\n",
      "34970/34970 [==============================] - 5s 136us/step - loss: 0.1351 - acc: 0.9419\n",
      "Epoch 61/100\n",
      "34970/34970 [==============================] - 5s 137us/step - loss: 0.1321 - acc: 0.9438\n",
      "Epoch 62/100\n",
      "34970/34970 [==============================] - 5s 134us/step - loss: 0.1280 - acc: 0.9454\n",
      "Epoch 63/100\n",
      "34970/34970 [==============================] - 5s 129us/step - loss: 0.1294 - acc: 0.9445\n",
      "Epoch 64/100\n",
      "34970/34970 [==============================] - 5s 135us/step - loss: 0.1231 - acc: 0.9478\n",
      "Epoch 65/100\n",
      "34970/34970 [==============================] - 5s 135us/step - loss: 0.1279 - acc: 0.9452\n",
      "Epoch 66/100\n",
      "34970/34970 [==============================] - 5s 139us/step - loss: 0.1261 - acc: 0.9467\n",
      "Epoch 67/100\n",
      "34970/34970 [==============================] - 5s 132us/step - loss: 0.1242 - acc: 0.9487\n",
      "Epoch 68/100\n",
      "34970/34970 [==============================] - 5s 136us/step - loss: 0.1242 - acc: 0.9484\n",
      "Epoch 69/100\n",
      "34970/34970 [==============================] - 5s 129us/step - loss: 0.1219 - acc: 0.9480\n",
      "Epoch 70/100\n",
      "34970/34970 [==============================] - 5s 139us/step - loss: 0.1202 - acc: 0.9494\n",
      "Epoch 71/100\n",
      "34970/34970 [==============================] - 5s 140us/step - loss: 0.1226 - acc: 0.9497\n",
      "Epoch 72/100\n",
      "34970/34970 [==============================] - 5s 149us/step - loss: 0.1153 - acc: 0.9510\n",
      "Epoch 73/100\n",
      "34970/34970 [==============================] - 5s 129us/step - loss: 0.1147 - acc: 0.9506\n",
      "Epoch 74/100\n",
      "34970/34970 [==============================] - 5s 132us/step - loss: 0.1196 - acc: 0.9506\n",
      "Epoch 75/100\n",
      "34970/34970 [==============================] - 5s 139us/step - loss: 0.1158 - acc: 0.9511\n",
      "Epoch 76/100\n",
      "34970/34970 [==============================] - 5s 131us/step - loss: 0.1166 - acc: 0.9513\n",
      "Epoch 77/100\n",
      "34970/34970 [==============================] - 5s 136us/step - loss: 0.1119 - acc: 0.9529\n",
      "Epoch 78/100\n",
      "34970/34970 [==============================] - 5s 142us/step - loss: 0.1114 - acc: 0.9532\n",
      "Epoch 79/100\n",
      "34970/34970 [==============================] - 5s 134us/step - loss: 0.1102 - acc: 0.9533\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34970/34970 [==============================] - 4s 121us/step - loss: 0.1110 - acc: 0.9542\n",
      "Epoch 81/100\n",
      "34970/34970 [==============================] - 5s 148us/step - loss: 0.1066 - acc: 0.9558\n",
      "Epoch 82/100\n",
      "34970/34970 [==============================] - 5s 132us/step - loss: 0.1062 - acc: 0.9560\n",
      "Epoch 83/100\n",
      "34970/34970 [==============================] - 4s 120us/step - loss: 0.1050 - acc: 0.9559\n",
      "Epoch 84/100\n",
      "34970/34970 [==============================] - 5s 135us/step - loss: 0.1039 - acc: 0.9560\n",
      "Epoch 85/100\n",
      "34970/34970 [==============================] - 5s 134us/step - loss: 0.1038 - acc: 0.9567\n",
      "Epoch 86/100\n",
      "34970/34970 [==============================] - 5s 132us/step - loss: 0.1064 - acc: 0.9565\n",
      "Epoch 87/100\n",
      "34970/34970 [==============================] - 4s 127us/step - loss: 0.1030 - acc: 0.9578\n",
      "Epoch 88/100\n",
      "34970/34970 [==============================] - 5s 133us/step - loss: 0.1016 - acc: 0.9578\n",
      "Epoch 89/100\n",
      "34970/34970 [==============================] - 4s 128us/step - loss: 0.1029 - acc: 0.9579\n",
      "Epoch 90/100\n",
      "34970/34970 [==============================] - 5s 135us/step - loss: 0.0977 - acc: 0.9593\n",
      "Epoch 91/100\n",
      "34970/34970 [==============================] - 5s 130us/step - loss: 0.1012 - acc: 0.9570\n",
      "Epoch 92/100\n",
      "34970/34970 [==============================] - 4s 127us/step - loss: 0.0967 - acc: 0.9603\n",
      "Epoch 93/100\n",
      "34970/34970 [==============================] - 4s 122us/step - loss: 0.1019 - acc: 0.9578\n",
      "Epoch 94/100\n",
      "34970/34970 [==============================] - 5s 138us/step - loss: 0.0976 - acc: 0.9606\n",
      "Epoch 95/100\n",
      "34970/34970 [==============================] - 4s 128us/step - loss: 0.0950 - acc: 0.9609\n",
      "Epoch 96/100\n",
      "34970/34970 [==============================] - ETA: 0s - loss: 0.0991 - acc: 0.959 - 5s 133us/step - loss: 0.0992 - acc: 0.9598\n",
      "Epoch 97/100\n",
      "34970/34970 [==============================] - 4s 116us/step - loss: 0.0949 - acc: 0.9603\n",
      "Epoch 98/100\n",
      "34970/34970 [==============================] - 4s 128us/step - loss: 0.1039 - acc: 0.9584\n",
      "Epoch 99/100\n",
      "34970/34970 [==============================] - 5s 141us/step - loss: 0.1004 - acc: 0.9599\n",
      "Epoch 100/100\n",
      "34970/34970 [==============================] - 5s 143us/step - loss: 0.0932 - acc: 0.9631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20984bcf160>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 200))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_train)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy: \", accuracy_score(Y_train, y_pred))\n",
    "print(\"recall: \", recall_score(Y_train, y_pred))\n",
    "print(\"precision: \", precision_score(Y_train, y_pred))\n",
    "print(\"F-1 score: \", f1_score(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "172205/172205 [==============================] - 20s 118us/step - loss: 0.2693 - acc: 0.9190\n",
      "Epoch 2/100\n",
      "172205/172205 [==============================] - 19s 108us/step - loss: 0.2695 - acc: 0.9188\n",
      "Epoch 3/100\n",
      "172205/172205 [==============================] - 19s 110us/step - loss: 0.2716 - acc: 0.9184\n",
      "Epoch 4/100\n",
      "172205/172205 [==============================] - 19s 111us/step - loss: 0.2714 - acc: 0.9186\n",
      "Epoch 5/100\n",
      "172205/172205 [==============================] - 19s 111us/step - loss: 0.2716 - acc: 0.9186\n",
      "Epoch 6/100\n",
      "172205/172205 [==============================] - 19s 110us/step - loss: 0.2726 - acc: 0.9186\n",
      "Epoch 7/100\n",
      "172205/172205 [==============================] - 20s 114us/step - loss: 0.2720 - acc: 0.9187\n",
      "Epoch 8/100\n",
      "172205/172205 [==============================] - 19s 111us/step - loss: 0.2728 - acc: 0.9189\n",
      "Epoch 9/100\n",
      "172205/172205 [==============================] - 19s 111us/step - loss: 0.2734 - acc: 0.9188\n",
      "Epoch 10/100\n",
      "172205/172205 [==============================] - 19s 112us/step - loss: 0.2739 - acc: 0.9187\n",
      "Epoch 11/100\n",
      "172205/172205 [==============================] - 19s 111us/step - loss: 0.2756 - acc: 0.9186\n",
      "Epoch 12/100\n",
      "172205/172205 [==============================] - 19s 110us/step - loss: 0.2759 - acc: 0.9185\n",
      "Epoch 13/100\n",
      "172205/172205 [==============================] - 19s 112us/step - loss: 0.2758 - acc: 0.9184\n",
      "Epoch 14/100\n",
      "172205/172205 [==============================] - 19s 112us/step - loss: 0.2767 - acc: 0.9185\n",
      "Epoch 15/100\n",
      "172205/172205 [==============================] - 22s 131us/step - loss: 0.2785 - acc: 0.9184\n",
      "Epoch 16/100\n",
      "172205/172205 [==============================] - 20s 119us/step - loss: 0.2800 - acc: 0.9181\n",
      "Epoch 17/100\n",
      "172205/172205 [==============================] - 19s 108us/step - loss: 0.2797 - acc: 0.9182\n",
      "Epoch 18/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.2801 - acc: 0.9181\n",
      "Epoch 19/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2816 - acc: 0.9178\n",
      "Epoch 20/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2822 - acc: 0.9177\n",
      "Epoch 21/100\n",
      "172205/172205 [==============================] - ETA: 0s - loss: 0.2832 - acc: 0.918 - 16s 94us/step - loss: 0.2832 - acc: 0.9180\n",
      "Epoch 22/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2829 - acc: 0.9177\n",
      "Epoch 23/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2832 - acc: 0.9178\n",
      "Epoch 24/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2833 - acc: 0.9175\n",
      "Epoch 25/100\n",
      "172205/172205 [==============================] - 17s 97us/step - loss: 0.2848 - acc: 0.9176\n",
      "Epoch 26/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2853 - acc: 0.9177\n",
      "Epoch 27/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2854 - acc: 0.9173\n",
      "Epoch 28/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2855 - acc: 0.9173\n",
      "Epoch 29/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2863 - acc: 0.9172\n",
      "Epoch 30/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2871 - acc: 0.9171\n",
      "Epoch 31/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2873 - acc: 0.9168\n",
      "Epoch 32/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2882 - acc: 0.9167\n",
      "Epoch 33/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2883 - acc: 0.9170\n",
      "Epoch 34/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2893 - acc: 0.9167\n",
      "Epoch 35/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2892 - acc: 0.9167\n",
      "Epoch 36/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2891 - acc: 0.9169\n",
      "Epoch 37/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2897 - acc: 0.9168\n",
      "Epoch 38/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2900 - acc: 0.9166\n",
      "Epoch 39/100\n",
      "172205/172205 [==============================] - 17s 96us/step - loss: 0.2906 - acc: 0.9166\n",
      "Epoch 40/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2915 - acc: 0.9165\n",
      "Epoch 41/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2922 - acc: 0.9164\n",
      "Epoch 42/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2924 - acc: 0.9162\n",
      "Epoch 43/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2939 - acc: 0.9160\n",
      "Epoch 44/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2944 - acc: 0.9158\n",
      "Epoch 45/100\n",
      "172205/172205 [==============================] - 17s 98us/step - loss: 0.2944 - acc: 0.9154\n",
      "Epoch 46/100\n",
      "172205/172205 [==============================] - 17s 97us/step - loss: 0.2947 - acc: 0.9155\n",
      "Epoch 47/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2952 - acc: 0.9154\n",
      "Epoch 48/100\n",
      "172205/172205 [==============================] - 16s 96us/step - loss: 0.2956 - acc: 0.9157\n",
      "Epoch 49/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2956 - acc: 0.9155\n",
      "Epoch 50/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.2950 - acc: 0.9159\n",
      "Epoch 51/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2946 - acc: 0.9156\n",
      "Epoch 52/100\n",
      "172205/172205 [==============================] - 16s 96us/step - loss: 0.2956 - acc: 0.9156\n",
      "Epoch 53/100\n",
      "172205/172205 [==============================] - 17s 101us/step - loss: 0.2960 - acc: 0.9158\n",
      "Epoch 54/100\n",
      "172205/172205 [==============================] - 17s 100us/step - loss: 0.2961 - acc: 0.9155\n",
      "Epoch 55/100\n",
      "172205/172205 [==============================] - 17s 98us/step - loss: 0.2968 - acc: 0.9152\n",
      "Epoch 56/100\n",
      "172205/172205 [==============================] - 17s 100us/step - loss: 0.2982 - acc: 0.9149\n",
      "Epoch 57/100\n",
      "172205/172205 [==============================] - 17s 99us/step - loss: 0.2995 - acc: 0.9145\n",
      "Epoch 58/100\n",
      "172205/172205 [==============================] - 17s 97us/step - loss: 0.2990 - acc: 0.9145\n",
      "Epoch 59/100\n",
      "172205/172205 [==============================] - 17s 98us/step - loss: 0.3009 - acc: 0.9147\n",
      "Epoch 60/100\n",
      "172205/172205 [==============================] - 17s 99us/step - loss: 0.2988 - acc: 0.9149\n",
      "Epoch 61/100\n",
      "172205/172205 [==============================] - 20s 117us/step - loss: 0.2996 - acc: 0.9149\n",
      "Epoch 62/100\n",
      "172205/172205 [==============================] - 18s 104us/step - loss: 0.2987 - acc: 0.9142\n",
      "Epoch 63/100\n",
      "172205/172205 [==============================] - 17s 98us/step - loss: 0.3001 - acc: 0.9146\n",
      "Epoch 64/100\n",
      "172205/172205 [==============================] - 17s 98us/step - loss: 0.2990 - acc: 0.9149\n",
      "Epoch 65/100\n",
      "172205/172205 [==============================] - 17s 99us/step - loss: 0.3005 - acc: 0.9147\n",
      "Epoch 66/100\n",
      "172205/172205 [==============================] - 17s 100us/step - loss: 0.3011 - acc: 0.9146\n",
      "Epoch 67/100\n",
      "172205/172205 [==============================] - 17s 101us/step - loss: 0.3027 - acc: 0.9141\n",
      "Epoch 68/100\n",
      "172205/172205 [==============================] - 17s 99us/step - loss: 0.3032 - acc: 0.9145\n",
      "Epoch 69/100\n",
      "172205/172205 [==============================] - 17s 100us/step - loss: 0.3040 - acc: 0.9144\n",
      "Epoch 70/100\n",
      "172205/172205 [==============================] - 17s 98us/step - loss: 0.3048 - acc: 0.9143\n",
      "Epoch 71/100\n",
      "172205/172205 [==============================] - 17s 98us/step - loss: 0.3046 - acc: 0.9139\n",
      "Epoch 72/100\n",
      "172205/172205 [==============================] - 17s 99us/step - loss: 0.3041 - acc: 0.9138\n",
      "Epoch 73/100\n",
      "172205/172205 [==============================] - 17s 97us/step - loss: 0.3034 - acc: 0.9142\n",
      "Epoch 74/100\n",
      "172205/172205 [==============================] - 17s 100us/step - loss: 0.3045 - acc: 0.9142\n",
      "Epoch 75/100\n",
      "172205/172205 [==============================] - 17s 99us/step - loss: 0.3054 - acc: 0.9138\n",
      "Epoch 76/100\n",
      "172205/172205 [==============================] - 17s 99us/step - loss: 0.3054 - acc: 0.9141\n",
      "Epoch 77/100\n",
      "172205/172205 [==============================] - 17s 99us/step - loss: 0.3070 - acc: 0.9138\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172205/172205 [==============================] - 17s 96us/step - loss: 0.3075 - acc: 0.9139\n",
      "Epoch 79/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3067 - acc: 0.9142\n",
      "Epoch 80/100\n",
      "172205/172205 [==============================] - 16s 93us/step - loss: 0.3057 - acc: 0.9143\n",
      "Epoch 81/100\n",
      "172205/172205 [==============================] - 16s 91us/step - loss: 0.3072 - acc: 0.9138\n",
      "Epoch 82/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.3068 - acc: 0.9137\n",
      "Epoch 83/100\n",
      "172205/172205 [==============================] - 16s 93us/step - loss: 0.3079 - acc: 0.9142\n",
      "Epoch 84/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.3085 - acc: 0.9137\n",
      "Epoch 85/100\n",
      "172205/172205 [==============================] - 16s 91us/step - loss: 0.3098 - acc: 0.9136\n",
      "Epoch 86/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3092 - acc: 0.9135\n",
      "Epoch 87/100\n",
      "172205/172205 [==============================] - 16s 90us/step - loss: 0.3094 - acc: 0.9133\n",
      "Epoch 88/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3106 - acc: 0.9130\n",
      "Epoch 89/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.3098 - acc: 0.9134\n",
      "Epoch 90/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.3109 - acc: 0.9134\n",
      "Epoch 91/100\n",
      "172205/172205 [==============================] - 16s 93us/step - loss: 0.3114 - acc: 0.9133\n",
      "Epoch 92/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3121 - acc: 0.9129\n",
      "Epoch 93/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3133 - acc: 0.9129\n",
      "Epoch 94/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.3125 - acc: 0.9127\n",
      "Epoch 95/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3148 - acc: 0.9123\n",
      "Epoch 96/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3143 - acc: 0.9124\n",
      "Epoch 97/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3147 - acc: 0.9121\n",
      "Epoch 98/100\n",
      "172205/172205 [==============================] - 16s 91us/step - loss: 0.3139 - acc: 0.9119\n",
      "Epoch 99/100\n",
      "172205/172205 [==============================] - 16s 93us/step - loss: 0.3142 - acc: 0.9118\n",
      "Epoch 100/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3147 - acc: 0.9114\n",
      "Epoch 1/100\n",
      "172205/172205 [==============================] - 18s 103us/step - loss: 0.2711 - acc: 0.9183\n",
      "Epoch 2/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2707 - acc: 0.9182\n",
      "Epoch 3/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.2731 - acc: 0.9177\n",
      "Epoch 4/100\n",
      "172205/172205 [==============================] - 16s 93us/step - loss: 0.2725 - acc: 0.9180\n",
      "Epoch 5/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.2732 - acc: 0.9180\n",
      "Epoch 6/100\n",
      "172205/172205 [==============================] - 16s 93us/step - loss: 0.2731 - acc: 0.9181\n",
      "Epoch 7/100\n",
      "172205/172205 [==============================] - 16s 93us/step - loss: 0.2740 - acc: 0.9183\n",
      "Epoch 8/100\n",
      "172205/172205 [==============================] - 17s 96us/step - loss: 0.2742 - acc: 0.9182\n",
      "Epoch 9/100\n",
      "172205/172205 [==============================] - 21s 121us/step - loss: 0.2755 - acc: 0.9179\n",
      "Epoch 10/100\n",
      "172205/172205 [==============================] - 23s 131us/step - loss: 0.2754 - acc: 0.9179\n",
      "Epoch 11/100\n",
      "172205/172205 [==============================] - 20s 116us/step - loss: 0.2760 - acc: 0.9178\n",
      "Epoch 12/100\n",
      "172205/172205 [==============================] - 19s 110us/step - loss: 0.2767 - acc: 0.9179\n",
      "Epoch 13/100\n",
      "172205/172205 [==============================] - 19s 113us/step - loss: 0.2768 - acc: 0.9178\n",
      "Epoch 14/100\n",
      "172205/172205 [==============================] - 21s 121us/step - loss: 0.2776 - acc: 0.9176\n",
      "Epoch 15/100\n",
      "172205/172205 [==============================] - 20s 117us/step - loss: 0.2788 - acc: 0.9176\n",
      "Epoch 16/100\n",
      "172205/172205 [==============================] - 20s 118us/step - loss: 0.2798 - acc: 0.9175\n",
      "Epoch 17/100\n",
      "172205/172205 [==============================] - 27s 159us/step - loss: 0.2824 - acc: 0.9172\n",
      "Epoch 18/100\n",
      "172205/172205 [==============================] - 25s 145us/step - loss: 0.2842 - acc: 0.9168\n",
      "Epoch 19/100\n",
      "172205/172205 [==============================] - 22s 129us/step - loss: 0.2829 - acc: 0.9169\n",
      "Epoch 20/100\n",
      "172205/172205 [==============================] - 22s 125us/step - loss: 0.2833 - acc: 0.9168\n",
      "Epoch 21/100\n",
      "172205/172205 [==============================] - 21s 124us/step - loss: 0.2829 - acc: 0.9167\n",
      "Epoch 22/100\n",
      "172205/172205 [==============================] - 23s 131us/step - loss: 0.2850 - acc: 0.9163\n",
      "Epoch 23/100\n",
      "172205/172205 [==============================] - 19s 112us/step - loss: 0.2845 - acc: 0.9166\n",
      "Epoch 24/100\n",
      "172205/172205 [==============================] - 20s 119us/step - loss: 0.2859 - acc: 0.9163\n",
      "Epoch 25/100\n",
      "172205/172205 [==============================] - 22s 129us/step - loss: 0.2879 - acc: 0.9161\n",
      "Epoch 26/100\n",
      "172205/172205 [==============================] - 22s 130us/step - loss: 0.2885 - acc: 0.9161\n",
      "Epoch 27/100\n",
      "172205/172205 [==============================] - 20s 117us/step - loss: 0.2887 - acc: 0.9165\n",
      "Epoch 28/100\n",
      "172205/172205 [==============================] - 24s 137us/step - loss: 0.2906 - acc: 0.9161\n",
      "Epoch 29/100\n",
      "172205/172205 [==============================] - 21s 119us/step - loss: 0.2893 - acc: 0.9165\n",
      "Epoch 30/100\n",
      "172205/172205 [==============================] - 21s 124us/step - loss: 0.2893 - acc: 0.9162\n",
      "Epoch 31/100\n",
      "172205/172205 [==============================] - 21s 120us/step - loss: 0.2900 - acc: 0.9158\n",
      "Epoch 32/100\n",
      "172205/172205 [==============================] - 19s 111us/step - loss: 0.2897 - acc: 0.9161\n",
      "Epoch 33/100\n",
      "172205/172205 [==============================] - 23s 134us/step - loss: 0.2909 - acc: 0.9156\n",
      "Epoch 34/100\n",
      "172205/172205 [==============================] - 21s 123us/step - loss: 0.2918 - acc: 0.9153\n",
      "Epoch 35/100\n",
      "172205/172205 [==============================] - 21s 122us/step - loss: 0.2926 - acc: 0.9157\n",
      "Epoch 36/100\n",
      "172205/172205 [==============================] - 21s 120us/step - loss: 0.2934 - acc: 0.9158\n",
      "Epoch 37/100\n",
      "172205/172205 [==============================] - 21s 123us/step - loss: 0.2945 - acc: 0.9158\n",
      "Epoch 38/100\n",
      "172205/172205 [==============================] - 21s 125us/step - loss: 0.2952 - acc: 0.9156\n",
      "Epoch 39/100\n",
      "172205/172205 [==============================] - 20s 115us/step - loss: 0.2941 - acc: 0.9156\n",
      "Epoch 40/100\n",
      "172205/172205 [==============================] - 4646s 27ms/step - loss: 0.2958 - acc: 0.9151\n",
      "Epoch 41/100\n",
      "172205/172205 [==============================] - 26s 152us/step - loss: 0.2993 - acc: 0.9146\n",
      "Epoch 42/100\n",
      "172205/172205 [==============================] - 19s 113us/step - loss: 0.2978 - acc: 0.9155\n",
      "Epoch 43/100\n",
      "172205/172205 [==============================] - 18s 103us/step - loss: 0.2970 - acc: 0.9156\n",
      "Epoch 44/100\n",
      "172205/172205 [==============================] - 17s 98us/step - loss: 0.2963 - acc: 0.9155\n",
      "Epoch 45/100\n",
      "172205/172205 [==============================] - 17s 99us/step - loss: 0.2976 - acc: 0.9153\n",
      "Epoch 46/100\n",
      "172205/172205 [==============================] - 16s 93us/step - loss: 0.2958 - acc: 0.9156\n",
      "Epoch 47/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.2958 - acc: 0.9156\n",
      "Epoch 48/100\n",
      "172205/172205 [==============================] - 17s 98us/step - loss: 0.2989 - acc: 0.9149\n",
      "Epoch 49/100\n",
      "172205/172205 [==============================] - 15s 90us/step - loss: 0.2978 - acc: 0.9152\n",
      "Epoch 50/100\n",
      "172205/172205 [==============================] - 18s 103us/step - loss: 0.2998 - acc: 0.9143\n",
      "Epoch 51/100\n",
      "172205/172205 [==============================] - 16s 90us/step - loss: 0.3007 - acc: 0.9146\n",
      "Epoch 52/100\n",
      "172205/172205 [==============================] - 14s 83us/step - loss: 0.3005 - acc: 0.9147\n",
      "Epoch 53/100\n",
      "172205/172205 [==============================] - 13s 77us/step - loss: 0.3007 - acc: 0.9148\n",
      "Epoch 54/100\n",
      "172205/172205 [==============================] - 14s 82us/step - loss: 0.2997 - acc: 0.9144\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172205/172205 [==============================] - 14s 79us/step - loss: 0.3000 - acc: 0.9146\n",
      "Epoch 56/100\n",
      "172205/172205 [==============================] - 14s 79us/step - loss: 0.2999 - acc: 0.9148\n",
      "Epoch 57/100\n",
      "172205/172205 [==============================] - 14s 81us/step - loss: 0.3006 - acc: 0.9146\n",
      "Epoch 58/100\n",
      "172205/172205 [==============================] - 16s 91us/step - loss: 0.3025 - acc: 0.9147\n",
      "Epoch 59/100\n",
      "172205/172205 [==============================] - 17s 97us/step - loss: 0.3018 - acc: 0.9144\n",
      "Epoch 60/100\n",
      "172205/172205 [==============================] - 14s 84us/step - loss: 0.3021 - acc: 0.9142\n",
      "Epoch 61/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3017 - acc: 0.9143\n",
      "Epoch 62/100\n",
      "172205/172205 [==============================] - 18s 102us/step - loss: 0.3022 - acc: 0.9144\n",
      "Epoch 63/100\n",
      "172205/172205 [==============================] - 15s 86us/step - loss: 0.3018 - acc: 0.9142\n",
      "Epoch 64/100\n",
      "172205/172205 [==============================] - 13s 78us/step - loss: 0.3031 - acc: 0.9142\n",
      "Epoch 65/100\n",
      "172205/172205 [==============================] - 13s 77us/step - loss: 0.3028 - acc: 0.9145\n",
      "Epoch 66/100\n",
      "172205/172205 [==============================] - 13s 77us/step - loss: 0.3015 - acc: 0.9146\n",
      "Epoch 67/100\n",
      "172205/172205 [==============================] - 16s 93us/step - loss: 0.3024 - acc: 0.9147\n",
      "Epoch 68/100\n",
      "172205/172205 [==============================] - 16s 91us/step - loss: 0.3036 - acc: 0.9149\n",
      "Epoch 69/100\n",
      "172205/172205 [==============================] - 22s 127us/step - loss: 0.3116 - acc: 0.9144\n",
      "Epoch 70/100\n",
      "172205/172205 [==============================] - 18s 102us/step - loss: 0.3039 - acc: 0.9145\n",
      "Epoch 71/100\n",
      "172205/172205 [==============================] - 19s 112us/step - loss: 0.3039 - acc: 0.9147\n",
      "Epoch 72/100\n",
      "172205/172205 [==============================] - 20s 117us/step - loss: 0.3054 - acc: 0.9145\n",
      "Epoch 73/100\n",
      "172205/172205 [==============================] - 20s 116us/step - loss: 0.3049 - acc: 0.9144\n",
      "Epoch 74/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.3029 - acc: 0.9145\n",
      "Epoch 75/100\n",
      "172205/172205 [==============================] - 15s 89us/step - loss: 0.3033 - acc: 0.9143\n",
      "Epoch 76/100\n",
      "172205/172205 [==============================] - 15s 89us/step - loss: 0.3027 - acc: 0.9144\n",
      "Epoch 77/100\n",
      "172205/172205 [==============================] - 17s 100us/step - loss: 0.3045 - acc: 0.9140\n",
      "Epoch 78/100\n",
      "172205/172205 [==============================] - 15s 88us/step - loss: 0.3040 - acc: 0.9144\n",
      "Epoch 79/100\n",
      "172205/172205 [==============================] - 16s 91us/step - loss: 0.3033 - acc: 0.9145\n",
      "Epoch 80/100\n",
      "172205/172205 [==============================] - 15s 87us/step - loss: 0.3024 - acc: 0.9146\n",
      "Epoch 81/100\n",
      "172205/172205 [==============================] - 15s 88us/step - loss: 0.3027 - acc: 0.9145\n",
      "Epoch 82/100\n",
      "172205/172205 [==============================] - 16s 90us/step - loss: 0.3018 - acc: 0.9143\n",
      "Epoch 83/100\n",
      "172205/172205 [==============================] - 15s 86us/step - loss: 0.3032 - acc: 0.9145\n",
      "Epoch 84/100\n",
      "172205/172205 [==============================] - 15s 88us/step - loss: 0.3030 - acc: 0.9140\n",
      "Epoch 85/100\n",
      "172205/172205 [==============================] - 15s 88us/step - loss: 0.3038 - acc: 0.9140\n",
      "Epoch 86/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3062 - acc: 0.9138\n",
      "Epoch 87/100\n",
      "172205/172205 [==============================] - 16s 90us/step - loss: 0.3065 - acc: 0.9136\n",
      "Epoch 88/100\n",
      "172205/172205 [==============================] - 15s 86us/step - loss: 0.3056 - acc: 0.9136\n",
      "Epoch 89/100\n",
      "172205/172205 [==============================] - 16s 92us/step - loss: 0.3056 - acc: 0.9137\n",
      "Epoch 90/100\n",
      "172205/172205 [==============================] - 15s 89us/step - loss: 0.3052 - acc: 0.9141\n",
      "Epoch 91/100\n",
      "172205/172205 [==============================] - 15s 88us/step - loss: 0.3036 - acc: 0.9139\n",
      "Epoch 92/100\n",
      "172205/172205 [==============================] - 15s 89us/step - loss: 0.3043 - acc: 0.9139\n",
      "Epoch 93/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.3038 - acc: 0.9136\n",
      "Epoch 94/100\n",
      "172205/172205 [==============================] - 15s 90us/step - loss: 0.3042 - acc: 0.9135\n",
      "Epoch 95/100\n",
      "172205/172205 [==============================] - 16s 96us/step - loss: 0.3051 - acc: 0.9136\n",
      "Epoch 96/100\n",
      "172205/172205 [==============================] - 16s 93us/step - loss: 0.3043 - acc: 0.9135\n",
      "Epoch 97/100\n",
      "172205/172205 [==============================] - 15s 90us/step - loss: 0.3050 - acc: 0.9133\n",
      "Epoch 98/100\n",
      "172205/172205 [==============================] - 15s 87us/step - loss: 0.3048 - acc: 0.9134\n",
      "Epoch 99/100\n",
      "172205/172205 [==============================] - 16s 95us/step - loss: 0.3054 - acc: 0.9131\n",
      "Epoch 100/100\n",
      "172205/172205 [==============================] - 16s 94us/step - loss: 0.3068 - acc: 0.9130\n",
      "Epoch 1/100\n",
      "172206/172206 [==============================] - 18s 106us/step - loss: 0.2694 - acc: 0.9190\n",
      "Epoch 2/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2687 - acc: 0.9190\n",
      "Epoch 3/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.2706 - acc: 0.9187\n",
      "Epoch 4/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.2707 - acc: 0.9186\n",
      "Epoch 5/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.2708 - acc: 0.9188\n",
      "Epoch 6/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.2719 - acc: 0.9185\n",
      "Epoch 7/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.2722 - acc: 0.9186\n",
      "Epoch 8/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.2729 - acc: 0.9183\n",
      "Epoch 9/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.2732 - acc: 0.9187\n",
      "Epoch 10/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.2728 - acc: 0.9188\n",
      "Epoch 11/100\n",
      "172206/172206 [==============================] - 18s 104us/step - loss: 0.2735 - acc: 0.9187\n",
      "Epoch 12/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.2739 - acc: 0.9187\n",
      "Epoch 13/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.2747 - acc: 0.9187\n",
      "Epoch 14/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.2755 - acc: 0.9184\n",
      "Epoch 15/100\n",
      "172206/172206 [==============================] - 18s 103us/step - loss: 0.2764 - acc: 0.9183\n",
      "Epoch 16/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.2764 - acc: 0.9183\n",
      "Epoch 17/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.2775 - acc: 0.9181\n",
      "Epoch 18/100\n",
      "172206/172206 [==============================] - 16s 95us/step - loss: 0.2789 - acc: 0.9181\n",
      "Epoch 19/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.2802 - acc: 0.9179\n",
      "Epoch 20/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.2825 - acc: 0.9178\n",
      "Epoch 21/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.2833 - acc: 0.9175\n",
      "Epoch 22/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.2840 - acc: 0.9175\n",
      "Epoch 23/100\n",
      "172206/172206 [==============================] - 16s 95us/step - loss: 0.2848 - acc: 0.9178\n",
      "Epoch 24/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.2860 - acc: 0.9174\n",
      "Epoch 25/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.2863 - acc: 0.9173\n",
      "Epoch 26/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.2865 - acc: 0.9173\n",
      "Epoch 27/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2864 - acc: 0.9173\n",
      "Epoch 28/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.2882 - acc: 0.9168\n",
      "Epoch 29/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.2886 - acc: 0.9168\n",
      "Epoch 30/100\n",
      "172206/172206 [==============================] - 16s 95us/step - loss: 0.2892 - acc: 0.9168\n",
      "Epoch 31/100\n",
      "172206/172206 [==============================] - 16s 95us/step - loss: 0.2886 - acc: 0.9164\n",
      "Epoch 32/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.2884 - acc: 0.9164\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.2897 - acc: 0.9164\n",
      "Epoch 34/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.2914 - acc: 0.9160\n",
      "Epoch 35/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.2906 - acc: 0.9159\n",
      "Epoch 36/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.2915 - acc: 0.9156\n",
      "Epoch 37/100\n",
      "172206/172206 [==============================] - 16s 95us/step - loss: 0.2916 - acc: 0.9157\n",
      "Epoch 38/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.2927 - acc: 0.9155\n",
      "Epoch 39/100\n",
      "172206/172206 [==============================] - 16s 95us/step - loss: 0.2932 - acc: 0.9155\n",
      "Epoch 40/100\n",
      "172206/172206 [==============================] - 16s 96us/step - loss: 0.2943 - acc: 0.9154\n",
      "Epoch 41/100\n",
      "172206/172206 [==============================] - 16s 95us/step - loss: 0.2949 - acc: 0.9154\n",
      "Epoch 42/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.2954 - acc: 0.9153\n",
      "Epoch 43/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.2958 - acc: 0.9151\n",
      "Epoch 44/100\n",
      "172206/172206 [==============================] - 16s 95us/step - loss: 0.2965 - acc: 0.9155\n",
      "Epoch 45/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.2976 - acc: 0.9155\n",
      "Epoch 46/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.2991 - acc: 0.9156\n",
      "Epoch 47/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.2999 - acc: 0.9159\n",
      "Epoch 48/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3011 - acc: 0.9159\n",
      "Epoch 49/100\n",
      "172206/172206 [==============================] - 18s 104us/step - loss: 0.3012 - acc: 0.9155\n",
      "Epoch 50/100\n",
      "172206/172206 [==============================] - 18s 105us/step - loss: 0.3011 - acc: 0.9157\n",
      "Epoch 51/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.3011 - acc: 0.9162\n",
      "Epoch 52/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3013 - acc: 0.9155\n",
      "Epoch 53/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.2990 - acc: 0.9154\n",
      "Epoch 54/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.2992 - acc: 0.9151\n",
      "Epoch 55/100\n",
      "172206/172206 [==============================] - 16s 96us/step - loss: 0.3008 - acc: 0.9151\n",
      "Epoch 56/100\n",
      "172206/172206 [==============================] - 16s 95us/step - loss: 0.3001 - acc: 0.9153\n",
      "Epoch 57/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3012 - acc: 0.9149\n",
      "Epoch 58/100\n",
      "172206/172206 [==============================] - 16s 96us/step - loss: 0.3008 - acc: 0.9149\n",
      "Epoch 59/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.3002 - acc: 0.9148\n",
      "Epoch 60/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3017 - acc: 0.9149\n",
      "Epoch 61/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.3007 - acc: 0.9149\n",
      "Epoch 62/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.3008 - acc: 0.9150\n",
      "Epoch 63/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.2997 - acc: 0.9148\n",
      "Epoch 64/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3011 - acc: 0.9148\n",
      "Epoch 65/100\n",
      "172206/172206 [==============================] - 16s 96us/step - loss: 0.3006 - acc: 0.9147\n",
      "Epoch 66/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.3015 - acc: 0.9146\n",
      "Epoch 67/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3039 - acc: 0.9146\n",
      "Epoch 68/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.3050 - acc: 0.9140\n",
      "Epoch 69/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3050 - acc: 0.9138\n",
      "Epoch 70/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.3049 - acc: 0.9140\n",
      "Epoch 71/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.3032 - acc: 0.9145\n",
      "Epoch 72/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.3032 - acc: 0.9147\n",
      "Epoch 73/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.3028 - acc: 0.9145\n",
      "Epoch 74/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.3029 - acc: 0.9143\n",
      "Epoch 75/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.3040 - acc: 0.9144\n",
      "Epoch 76/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3051 - acc: 0.9144\n",
      "Epoch 77/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.3060 - acc: 0.9146\n",
      "Epoch 78/100\n",
      "172206/172206 [==============================] - 18s 103us/step - loss: 0.3070 - acc: 0.9149\n",
      "Epoch 79/100\n",
      "172206/172206 [==============================] - 22s 129us/step - loss: 0.3106 - acc: 0.9143\n",
      "Epoch 80/100\n",
      "172206/172206 [==============================] - 18s 106us/step - loss: 0.3077 - acc: 0.9147\n",
      "Epoch 81/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.3073 - acc: 0.9139\n",
      "Epoch 82/100\n",
      "172206/172206 [==============================] - 15s 86us/step - loss: 0.3066 - acc: 0.9143\n",
      "Epoch 83/100\n",
      "172206/172206 [==============================] - 15s 86us/step - loss: 0.3051 - acc: 0.9145\n",
      "Epoch 84/100\n",
      "172206/172206 [==============================] - 19s 108us/step - loss: 0.3069 - acc: 0.9143\n",
      "Epoch 85/100\n",
      "172206/172206 [==============================] - 19s 109us/step - loss: 0.3089 - acc: 0.9138\n",
      "Epoch 86/100\n",
      "172206/172206 [==============================] - 19s 109us/step - loss: 0.3073 - acc: 0.9141\n",
      "Epoch 87/100\n",
      "172206/172206 [==============================] - 21s 124us/step - loss: 0.3091 - acc: 0.9137\n",
      "Epoch 88/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.3094 - acc: 0.9139\n",
      "Epoch 89/100\n",
      "172206/172206 [==============================] - 20s 117us/step - loss: 0.3094 - acc: 0.9140\n",
      "Epoch 90/100\n",
      "172206/172206 [==============================] - 19s 108us/step - loss: 0.3104 - acc: 0.9138\n",
      "Epoch 91/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.3103 - acc: 0.9142\n",
      "Epoch 92/100\n",
      "172206/172206 [==============================] - 18s 102us/step - loss: 0.3105 - acc: 0.9137\n",
      "Epoch 93/100\n",
      "172206/172206 [==============================] - 18s 104us/step - loss: 0.3109 - acc: 0.9137\n",
      "Epoch 94/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.3084 - acc: 0.9130\n",
      "Epoch 95/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.3079 - acc: 0.9133\n",
      "Epoch 96/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.3080 - acc: 0.9139\n",
      "Epoch 97/100\n",
      "172206/172206 [==============================] - 18s 106us/step - loss: 0.3098 - acc: 0.9133\n",
      "Epoch 98/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3102 - acc: 0.9133\n",
      "Epoch 99/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.3089 - acc: 0.9138\n",
      "Epoch 100/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.3076 - acc: 0.9141\n",
      "Epoch 1/100\n",
      "172206/172206 [==============================] - 19s 108us/step - loss: 0.2716 - acc: 0.9184\n",
      "Epoch 2/100\n",
      "172206/172206 [==============================] - 15s 90us/step - loss: 0.2715 - acc: 0.9183\n",
      "Epoch 3/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2725 - acc: 0.9180\n",
      "Epoch 4/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2722 - acc: 0.9183\n",
      "Epoch 5/100\n",
      "172206/172206 [==============================] - 23s 134us/step - loss: 0.2742 - acc: 0.9179\n",
      "Epoch 6/100\n",
      "172206/172206 [==============================] - 18s 104us/step - loss: 0.2736 - acc: 0.9180\n",
      "Epoch 7/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.2730 - acc: 0.9183\n",
      "Epoch 8/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.2740 - acc: 0.9183\n",
      "Epoch 9/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.2752 - acc: 0.9182\n",
      "Epoch 10/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.2756 - acc: 0.9181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2755 - acc: 0.9181\n",
      "Epoch 12/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2767 - acc: 0.9180\n",
      "Epoch 13/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2780 - acc: 0.9180\n",
      "Epoch 14/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2780 - acc: 0.9179\n",
      "Epoch 15/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2793 - acc: 0.9178\n",
      "Epoch 16/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2808 - acc: 0.9176\n",
      "Epoch 17/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2811 - acc: 0.9175\n",
      "Epoch 18/100\n",
      "172206/172206 [==============================] - 15s 87us/step - loss: 0.2808 - acc: 0.9173\n",
      "Epoch 19/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2809 - acc: 0.9174\n",
      "Epoch 20/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2824 - acc: 0.9175\n",
      "Epoch 21/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2848 - acc: 0.9172\n",
      "Epoch 22/100\n",
      "172206/172206 [==============================] - 15s 90us/step - loss: 0.2866 - acc: 0.9172\n",
      "Epoch 23/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.2870 - acc: 0.9170\n",
      "Epoch 24/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2865 - acc: 0.9169\n",
      "Epoch 25/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2859 - acc: 0.9172\n",
      "Epoch 26/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2887 - acc: 0.9168\n",
      "Epoch 27/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2892 - acc: 0.9166\n",
      "Epoch 28/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.2897 - acc: 0.9167\n",
      "Epoch 29/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2904 - acc: 0.9163\n",
      "Epoch 30/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2884 - acc: 0.9165\n",
      "Epoch 31/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2889 - acc: 0.9165\n",
      "Epoch 32/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2889 - acc: 0.9165\n",
      "Epoch 33/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2898 - acc: 0.9163\n",
      "Epoch 34/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2908 - acc: 0.9161\n",
      "Epoch 35/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2923 - acc: 0.9156\n",
      "Epoch 36/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.2936 - acc: 0.9158\n",
      "Epoch 37/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2930 - acc: 0.9159\n",
      "Epoch 38/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2925 - acc: 0.9158\n",
      "Epoch 39/100\n",
      "172206/172206 [==============================] - 15s 90us/step - loss: 0.2921 - acc: 0.9158\n",
      "Epoch 40/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2907 - acc: 0.9157\n",
      "Epoch 41/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2917 - acc: 0.9158\n",
      "Epoch 42/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.2929 - acc: 0.9156\n",
      "Epoch 43/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.2955 - acc: 0.9156\n",
      "Epoch 44/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.2972 - acc: 0.9159\n",
      "Epoch 45/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.2956 - acc: 0.9157\n",
      "Epoch 46/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.2960 - acc: 0.9155\n",
      "Epoch 47/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2968 - acc: 0.9156\n",
      "Epoch 48/100\n",
      "172206/172206 [==============================] - 15s 90us/step - loss: 0.2973 - acc: 0.9156\n",
      "Epoch 49/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2981 - acc: 0.9158\n",
      "Epoch 50/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2989 - acc: 0.9155\n",
      "Epoch 51/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2969 - acc: 0.9153\n",
      "Epoch 52/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2968 - acc: 0.9153\n",
      "Epoch 53/100\n",
      "172206/172206 [==============================] - 15s 86us/step - loss: 0.2983 - acc: 0.9152\n",
      "Epoch 54/100\n",
      "172206/172206 [==============================] - 20s 116us/step - loss: 0.2989 - acc: 0.9151\n",
      "Epoch 55/100\n",
      "172206/172206 [==============================] - 18s 106us/step - loss: 0.2988 - acc: 0.9150\n",
      "Epoch 56/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2979 - acc: 0.9152\n",
      "Epoch 57/100\n",
      "172206/172206 [==============================] - 19s 109us/step - loss: 0.2991 - acc: 0.9150\n",
      "Epoch 58/100\n",
      "172206/172206 [==============================] - 20s 118us/step - loss: 0.3010 - acc: 0.9149\n",
      "Epoch 59/100\n",
      "172206/172206 [==============================] - 18s 103us/step - loss: 0.3010 - acc: 0.9148\n",
      "Epoch 60/100\n",
      "172206/172206 [==============================] - 22s 129us/step - loss: 0.3034 - acc: 0.9139\n",
      "Epoch 61/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.3023 - acc: 0.9139\n",
      "Epoch 62/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.3020 - acc: 0.9139\n",
      "Epoch 63/100\n",
      "172206/172206 [==============================] - 15s 87us/step - loss: 0.3019 - acc: 0.9141\n",
      "Epoch 64/100\n",
      "172206/172206 [==============================] - 19s 111us/step - loss: 0.3011 - acc: 0.9138\n",
      "Epoch 65/100\n",
      "172206/172206 [==============================] - 19s 109us/step - loss: 0.3009 - acc: 0.9143\n",
      "Epoch 66/100\n",
      "172206/172206 [==============================] - 19s 112us/step - loss: 0.3021 - acc: 0.9141\n",
      "Epoch 67/100\n",
      "172206/172206 [==============================] - 18s 107us/step - loss: 0.3028 - acc: 0.9145\n",
      "Epoch 68/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3043 - acc: 0.9146\n",
      "Epoch 69/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.3039 - acc: 0.9139\n",
      "Epoch 70/100\n",
      "172206/172206 [==============================] - 20s 117us/step - loss: 0.3050 - acc: 0.9137\n",
      "Epoch 71/100\n",
      "172206/172206 [==============================] - 19s 109us/step - loss: 0.3056 - acc: 0.9133\n",
      "Epoch 72/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3050 - acc: 0.9133\n",
      "Epoch 73/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3054 - acc: 0.9133\n",
      "Epoch 74/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3062 - acc: 0.9129\n",
      "Epoch 75/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3066 - acc: 0.9132\n",
      "Epoch 76/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3051 - acc: 0.91290s - loss: 0.305\n",
      "Epoch 77/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3066 - acc: 0.9128\n",
      "Epoch 78/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3061 - acc: 0.9132\n",
      "Epoch 79/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3065 - acc: 0.9126\n",
      "Epoch 80/100\n",
      "172206/172206 [==============================] - 18s 105us/step - loss: 0.3075 - acc: 0.9125\n",
      "Epoch 81/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.3092 - acc: 0.9121\n",
      "Epoch 82/100\n",
      "172206/172206 [==============================] - 18s 102us/step - loss: 0.3099 - acc: 0.9123\n",
      "Epoch 83/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3098 - acc: 0.9123\n",
      "Epoch 84/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.3091 - acc: 0.9126\n",
      "Epoch 85/100\n",
      "172206/172206 [==============================] - 20s 115us/step - loss: 0.3103 - acc: 0.9125\n",
      "Epoch 86/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3117 - acc: 0.9122\n",
      "Epoch 87/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.3118 - acc: 0.9124\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3125 - acc: 0.9119\n",
      "Epoch 89/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3147 - acc: 0.9121\n",
      "Epoch 90/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.3140 - acc: 0.9123\n",
      "Epoch 91/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3139 - acc: 0.9128\n",
      "Epoch 92/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3138 - acc: 0.9124\n",
      "Epoch 93/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3153 - acc: 0.9127\n",
      "Epoch 94/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.3137 - acc: 0.9129\n",
      "Epoch 95/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.3145 - acc: 0.9129\n",
      "Epoch 96/100\n",
      "172206/172206 [==============================] - 15s 87us/step - loss: 0.3118 - acc: 0.9130\n",
      "Epoch 97/100\n",
      "172206/172206 [==============================] - 15s 87us/step - loss: 0.3112 - acc: 0.9130\n",
      "Epoch 98/100\n",
      "172206/172206 [==============================] - 15s 86us/step - loss: 0.3126 - acc: 0.9132\n",
      "Epoch 99/100\n",
      "172206/172206 [==============================] - 14s 84us/step - loss: 0.3125 - acc: 0.9125\n",
      "Epoch 100/100\n",
      "172206/172206 [==============================] - 15s 87us/step - loss: 0.3131 - acc: 0.9126\n",
      "Epoch 1/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.2704 - acc: 0.9189\n",
      "Epoch 2/100\n",
      "172206/172206 [==============================] - 15s 90us/step - loss: 0.2706 - acc: 0.9188\n",
      "Epoch 3/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2699 - acc: 0.9187\n",
      "Epoch 4/100\n",
      "172206/172206 [==============================] - 15s 87us/step - loss: 0.2714 - acc: 0.9187\n",
      "Epoch 5/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2715 - acc: 0.9186\n",
      "Epoch 6/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2721 - acc: 0.9187\n",
      "Epoch 7/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2727 - acc: 0.9189\n",
      "Epoch 8/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2733 - acc: 0.9188\n",
      "Epoch 9/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2731 - acc: 0.9187\n",
      "Epoch 10/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.2744 - acc: 0.9188\n",
      "Epoch 11/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2751 - acc: 0.9186\n",
      "Epoch 12/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2763 - acc: 0.9186\n",
      "Epoch 13/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.2779 - acc: 0.9186\n",
      "Epoch 14/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2769 - acc: 0.9185\n",
      "Epoch 15/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2770 - acc: 0.9184\n",
      "Epoch 16/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2793 - acc: 0.9181\n",
      "Epoch 17/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2794 - acc: 0.9181\n",
      "Epoch 18/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2803 - acc: 0.9178\n",
      "Epoch 19/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2807 - acc: 0.9177\n",
      "Epoch 20/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2814 - acc: 0.9178\n",
      "Epoch 21/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2823 - acc: 0.9178\n",
      "Epoch 22/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2837 - acc: 0.9176\n",
      "Epoch 23/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2861 - acc: 0.9177\n",
      "Epoch 24/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2877 - acc: 0.9176\n",
      "Epoch 25/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2882 - acc: 0.9173\n",
      "Epoch 26/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2878 - acc: 0.9166\n",
      "Epoch 27/100\n",
      "172206/172206 [==============================] - 15s 90us/step - loss: 0.2862 - acc: 0.9161\n",
      "Epoch 28/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2864 - acc: 0.9161\n",
      "Epoch 29/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2870 - acc: 0.9161\n",
      "Epoch 30/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2895 - acc: 0.9162\n",
      "Epoch 31/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2909 - acc: 0.9162\n",
      "Epoch 32/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2928 - acc: 0.9158\n",
      "Epoch 33/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2925 - acc: 0.9163\n",
      "Epoch 34/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2920 - acc: 0.9162\n",
      "Epoch 35/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2928 - acc: 0.9164\n",
      "Epoch 36/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2935 - acc: 0.9163\n",
      "Epoch 37/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2931 - acc: 0.9164\n",
      "Epoch 38/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2946 - acc: 0.9162\n",
      "Epoch 39/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2940 - acc: 0.9166\n",
      "Epoch 40/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2945 - acc: 0.9161\n",
      "Epoch 41/100\n",
      "172206/172206 [==============================] - 16s 90us/step - loss: 0.2939 - acc: 0.9161\n",
      "Epoch 42/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2953 - acc: 0.9160\n",
      "Epoch 43/100\n",
      "172206/172206 [==============================] - 15s 89us/step - loss: 0.2947 - acc: 0.9159\n",
      "Epoch 44/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.2961 - acc: 0.9158\n",
      "Epoch 45/100\n",
      "172206/172206 [==============================] - 16s 96us/step - loss: 0.2974 - acc: 0.9157\n",
      "Epoch 46/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2975 - acc: 0.9155\n",
      "Epoch 47/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.2987 - acc: 0.9154\n",
      "Epoch 48/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.3013 - acc: 0.9156\n",
      "Epoch 49/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2995 - acc: 0.9152\n",
      "Epoch 50/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.2987 - acc: 0.9149\n",
      "Epoch 51/100\n",
      "172206/172206 [==============================] - 15s 88us/step - loss: 0.3002 - acc: 0.9153\n",
      "Epoch 52/100\n",
      "172206/172206 [==============================] - 15s 90us/step - loss: 0.3017 - acc: 0.9151\n",
      "Epoch 53/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.3004 - acc: 0.9153\n",
      "Epoch 54/100\n",
      "172206/172206 [==============================] - 15s 90us/step - loss: 0.3016 - acc: 0.9153\n",
      "Epoch 55/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3010 - acc: 0.9152\n",
      "Epoch 56/100\n",
      "172206/172206 [==============================] - 20s 118us/step - loss: 0.3017 - acc: 0.9147\n",
      "Epoch 57/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.2997 - acc: 0.9149\n",
      "Epoch 58/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3007 - acc: 0.9143\n",
      "Epoch 59/100\n",
      "172206/172206 [==============================] - 18s 103us/step - loss: 0.3005 - acc: 0.9143\n",
      "Epoch 60/100\n",
      "172206/172206 [==============================] - 18s 104us/step - loss: 0.3012 - acc: 0.9141\n",
      "Epoch 61/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.3014 - acc: 0.9140\n",
      "Epoch 62/100\n",
      "172206/172206 [==============================] - 18s 102us/step - loss: 0.3028 - acc: 0.9136\n",
      "Epoch 63/100\n",
      "172206/172206 [==============================] - 21s 122us/step - loss: 0.3045 - acc: 0.9134\n",
      "Epoch 64/100\n",
      "172206/172206 [==============================] - 18s 106us/step - loss: 0.3053 - acc: 0.9128\n",
      "Epoch 65/100\n",
      "172206/172206 [==============================] - 18s 104us/step - loss: 0.3063 - acc: 0.9132\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172206/172206 [==============================] - 18s 102us/step - loss: 0.3045 - acc: 0.9134\n",
      "Epoch 67/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.3043 - acc: 0.9136\n",
      "Epoch 68/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3042 - acc: 0.9133\n",
      "Epoch 69/100\n",
      "172206/172206 [==============================] - 18s 103us/step - loss: 0.3043 - acc: 0.9136\n",
      "Epoch 70/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3045 - acc: 0.9140\n",
      "Epoch 71/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3036 - acc: 0.9140\n",
      "Epoch 72/100\n",
      "172206/172206 [==============================] - 17s 97us/step - loss: 0.3038 - acc: 0.9139\n",
      "Epoch 73/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.3035 - acc: 0.9138\n",
      "Epoch 74/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.3041 - acc: 0.9141\n",
      "Epoch 75/100\n",
      "172206/172206 [==============================] - 17s 98us/step - loss: 0.3042 - acc: 0.9144\n",
      "Epoch 76/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.3046 - acc: 0.9140\n",
      "Epoch 77/100\n",
      "172206/172206 [==============================] - 17s 100us/step - loss: 0.3048 - acc: 0.9142\n",
      "Epoch 78/100\n",
      "172206/172206 [==============================] - 18s 103us/step - loss: 0.3071 - acc: 0.9140\n",
      "Epoch 79/100\n",
      "172206/172206 [==============================] - 19s 109us/step - loss: 0.3084 - acc: 0.9137\n",
      "Epoch 80/100\n",
      "172206/172206 [==============================] - 17s 101us/step - loss: 0.3088 - acc: 0.9138\n",
      "Epoch 81/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.3074 - acc: 0.9140\n",
      "Epoch 82/100\n",
      "172206/172206 [==============================] - 16s 95us/step - loss: 0.3095 - acc: 0.9134\n",
      "Epoch 83/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.3090 - acc: 0.9136\n",
      "Epoch 84/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.3097 - acc: 0.9133\n",
      "Epoch 85/100\n",
      "172206/172206 [==============================] - 15s 90us/step - loss: 0.3090 - acc: 0.9134\n",
      "Epoch 86/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.3107 - acc: 0.9138\n",
      "Epoch 87/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.3089 - acc: 0.9138\n",
      "Epoch 88/100\n",
      "172206/172206 [==============================] - 21s 119us/step - loss: 0.3140 - acc: 0.9132\n",
      "Epoch 89/100\n",
      "172206/172206 [==============================] - 19s 110us/step - loss: 0.3138 - acc: 0.9137\n",
      "Epoch 90/100\n",
      "172206/172206 [==============================] - 18s 106us/step - loss: 0.3135 - acc: 0.9136\n",
      "Epoch 91/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.3149 - acc: 0.9139\n",
      "Epoch 92/100\n",
      "172206/172206 [==============================] - 16s 91us/step - loss: 0.3148 - acc: 0.9141\n",
      "Epoch 93/100\n",
      "172206/172206 [==============================] - 15s 90us/step - loss: 0.3162 - acc: 0.9137\n",
      "Epoch 94/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.3149 - acc: 0.9136\n",
      "Epoch 95/100\n",
      "172206/172206 [==============================] - 16s 94us/step - loss: 0.3132 - acc: 0.9133\n",
      "Epoch 96/100\n",
      "172206/172206 [==============================] - 16s 92us/step - loss: 0.3124 - acc: 0.9130\n",
      "Epoch 97/100\n",
      "172206/172206 [==============================] - 16s 93us/step - loss: 0.3114 - acc: 0.9130\n",
      "Epoch 98/100\n",
      "172206/172206 [==============================] - 19s 109us/step - loss: 0.3121 - acc: 0.9131\n",
      "Epoch 99/100\n",
      "172206/172206 [==============================] - 17s 99us/step - loss: 0.3109 - acc: 0.9131\n",
      "Epoch 100/100\n",
      "172206/172206 [==============================] - 17s 96us/step - loss: 0.3109 - acc: 0.9130\n",
      "Epoch 1/100\n",
      "215257/215257 [==============================] - 26s 121us/step - loss: 0.2704 - acc: 0.9187\n",
      "Epoch 2/100\n",
      "215257/215257 [==============================] - 30s 140us/step - loss: 0.2702 - acc: 0.9186\n",
      "Epoch 3/100\n",
      "215257/215257 [==============================] - 24s 110us/step - loss: 0.2709 - acc: 0.9186\n",
      "Epoch 4/100\n",
      "215257/215257 [==============================] - 23s 105us/step - loss: 0.2722 - acc: 0.9186\n",
      "Epoch 5/100\n",
      "215257/215257 [==============================] - 23s 106us/step - loss: 0.2729 - acc: 0.9186\n",
      "Epoch 6/100\n",
      "215257/215257 [==============================] - 24s 110us/step - loss: 0.2734 - acc: 0.9184\n",
      "Epoch 7/100\n",
      "215257/215257 [==============================] - 23s 108us/step - loss: 0.2739 - acc: 0.9186\n",
      "Epoch 8/100\n",
      "215257/215257 [==============================] - 24s 113us/step - loss: 0.2754 - acc: 0.9185\n",
      "Epoch 9/100\n",
      "215257/215257 [==============================] - 24s 110us/step - loss: 0.2760 - acc: 0.9185\n",
      "Epoch 10/100\n",
      "215257/215257 [==============================] - 24s 112us/step - loss: 0.2754 - acc: 0.9185\n",
      "Epoch 11/100\n",
      "215257/215257 [==============================] - 23s 109us/step - loss: 0.2767 - acc: 0.9185\n",
      "Epoch 12/100\n",
      "215257/215257 [==============================] - 20s 91us/step - loss: 0.2781 - acc: 0.9181\n",
      "Epoch 13/100\n",
      "215257/215257 [==============================] - 21s 96us/step - loss: 0.2792 - acc: 0.9181\n",
      "Epoch 14/100\n",
      "215257/215257 [==============================] - 20s 91us/step - loss: 0.2813 - acc: 0.9180\n",
      "Epoch 15/100\n",
      "215257/215257 [==============================] - 20s 92us/step - loss: 0.2815 - acc: 0.9179\n",
      "Epoch 16/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2816 - acc: 0.9178\n",
      "Epoch 17/100\n",
      "215257/215257 [==============================] - 20s 94us/step - loss: 0.2832 - acc: 0.9177\n",
      "Epoch 18/100\n",
      "215257/215257 [==============================] - 20s 92us/step - loss: 0.2857 - acc: 0.9173\n",
      "Epoch 19/100\n",
      "215257/215257 [==============================] - 20s 95us/step - loss: 0.2859 - acc: 0.9172\n",
      "Epoch 20/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2860 - acc: 0.9171\n",
      "Epoch 21/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2868 - acc: 0.9172\n",
      "Epoch 22/100\n",
      "215257/215257 [==============================] - 20s 92us/step - loss: 0.2878 - acc: 0.9172\n",
      "Epoch 23/100\n",
      "215257/215257 [==============================] - 21s 96us/step - loss: 0.2873 - acc: 0.9170\n",
      "Epoch 24/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2877 - acc: 0.9169\n",
      "Epoch 25/100\n",
      "215257/215257 [==============================] - 20s 94us/step - loss: 0.2889 - acc: 0.9168\n",
      "Epoch 26/100\n",
      "215257/215257 [==============================] - 20s 92us/step - loss: 0.2907 - acc: 0.9168\n",
      "Epoch 27/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2920 - acc: 0.9162\n",
      "Epoch 28/100\n",
      "215257/215257 [==============================] - 20s 95us/step - loss: 0.2930 - acc: 0.9163\n",
      "Epoch 29/100\n",
      "215257/215257 [==============================] - 21s 96us/step - loss: 0.2945 - acc: 0.9160\n",
      "Epoch 30/100\n",
      "215257/215257 [==============================] - 20s 92us/step - loss: 0.2947 - acc: 0.9160\n",
      "Epoch 31/100\n",
      "215257/215257 [==============================] - 21s 95us/step - loss: 0.2950 - acc: 0.9160\n",
      "Epoch 32/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2950 - acc: 0.9158\n",
      "Epoch 33/100\n",
      "215257/215257 [==============================] - 20s 95us/step - loss: 0.2960 - acc: 0.9159\n",
      "Epoch 34/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2959 - acc: 0.9156\n",
      "Epoch 35/100\n",
      "215257/215257 [==============================] - 21s 95us/step - loss: 0.2952 - acc: 0.9158\n",
      "Epoch 36/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2960 - acc: 0.9157\n",
      "Epoch 37/100\n",
      "215257/215257 [==============================] - 20s 94us/step - loss: 0.2959 - acc: 0.9155\n",
      "Epoch 38/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2968 - acc: 0.9156\n",
      "Epoch 39/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2985 - acc: 0.9158\n",
      "Epoch 40/100\n",
      "215257/215257 [==============================] - 20s 94us/step - loss: 0.2994 - acc: 0.9155\n",
      "Epoch 41/100\n",
      "215257/215257 [==============================] - 20s 94us/step - loss: 0.2995 - acc: 0.9153\n",
      "Epoch 42/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.2987 - acc: 0.9154\n",
      "Epoch 43/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.3007 - acc: 0.9156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.3015 - acc: 0.9154\n",
      "Epoch 45/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.3007 - acc: 0.9155\n",
      "Epoch 46/100\n",
      "215257/215257 [==============================] - 20s 92us/step - loss: 0.3011 - acc: 0.9153\n",
      "Epoch 47/100\n",
      "215257/215257 [==============================] - 21s 96us/step - loss: 0.3011 - acc: 0.9154\n",
      "Epoch 48/100\n",
      "215257/215257 [==============================] - 21s 99us/step - loss: 0.3005 - acc: 0.9148\n",
      "Epoch 49/100\n",
      "215257/215257 [==============================] - 23s 107us/step - loss: 0.3011 - acc: 0.9143\n",
      "Epoch 50/100\n",
      "215257/215257 [==============================] - 22s 104us/step - loss: 0.3040 - acc: 0.9142\n",
      "Epoch 51/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.3035 - acc: 0.9137\n",
      "Epoch 52/100\n",
      "215257/215257 [==============================] - 20s 95us/step - loss: 0.3024 - acc: 0.9138\n",
      "Epoch 53/100\n",
      "215257/215257 [==============================] - 20s 94us/step - loss: 0.3045 - acc: 0.9138\n",
      "Epoch 54/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.3049 - acc: 0.9139\n",
      "Epoch 55/100\n",
      "215257/215257 [==============================] - 22s 102us/step - loss: 0.3067 - acc: 0.9132\n",
      "Epoch 56/100\n",
      "215257/215257 [==============================] - 20s 94us/step - loss: 0.3073 - acc: 0.9131\n",
      "Epoch 57/100\n",
      "215257/215257 [==============================] - 29s 133us/step - loss: 0.3104 - acc: 0.9125\n",
      "Epoch 58/100\n",
      "215257/215257 [==============================] - 21s 96us/step - loss: 0.3078 - acc: 0.9132\n",
      "Epoch 59/100\n",
      "215257/215257 [==============================] - 21s 96us/step - loss: 0.3083 - acc: 0.9135\n",
      "Epoch 60/100\n",
      "215257/215257 [==============================] - 24s 114us/step - loss: 0.3079 - acc: 0.9132\n",
      "Epoch 61/100\n",
      "215257/215257 [==============================] - 27s 124us/step - loss: 0.3086 - acc: 0.9134\n",
      "Epoch 62/100\n",
      "215257/215257 [==============================] - 21s 96us/step - loss: 0.3072 - acc: 0.9132\n",
      "Epoch 63/100\n",
      "215257/215257 [==============================] - 21s 96us/step - loss: 0.3069 - acc: 0.9137\n",
      "Epoch 64/100\n",
      "215257/215257 [==============================] - 20s 91us/step - loss: 0.3063 - acc: 0.9139\n",
      "Epoch 65/100\n",
      "215257/215257 [==============================] - 20s 92us/step - loss: 0.3069 - acc: 0.9138\n",
      "Epoch 66/100\n",
      "215257/215257 [==============================] - 20s 92us/step - loss: 0.3068 - acc: 0.9139\n",
      "Epoch 67/100\n",
      "215257/215257 [==============================] - 20s 93us/step - loss: 0.3074 - acc: 0.9139\n",
      "Epoch 68/100\n",
      "215257/215257 [==============================] - 21s 96us/step - loss: 0.3090 - acc: 0.9135\n",
      "Epoch 69/100\n",
      "215257/215257 [==============================] - 20s 94us/step - loss: 0.3080 - acc: 0.9137\n",
      "Epoch 70/100\n",
      "215257/215257 [==============================] - 22s 102us/step - loss: 0.3084 - acc: 0.9138\n",
      "Epoch 71/100\n",
      "215257/215257 [==============================] - 26s 119us/step - loss: 0.3120 - acc: 0.9138\n",
      "Epoch 72/100\n",
      "215257/215257 [==============================] - 25s 115us/step - loss: 0.3565 - acc: 0.9149\n",
      "Epoch 73/100\n",
      "215257/215257 [==============================] - 25s 115us/step - loss: 0.4317 - acc: 0.9156\n",
      "Epoch 74/100\n",
      "215257/215257 [==============================] - 25s 117us/step - loss: 0.3146 - acc: 0.9137\n",
      "Epoch 75/100\n",
      "215257/215257 [==============================] - 26s 120us/step - loss: 0.3079 - acc: 0.9140\n",
      "Epoch 76/100\n",
      " 85475/215257 [==========>...................] - ETA: 15s - loss: 0.3038 - acc: 0.9154"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-3000e76c50c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m                            cv = 5)\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ANACONDA\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ANACONDA\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ANACONDA\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\ANACONDA\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ANACONDA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ANACONDA\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ANACONDA\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu', input_dim = 200))\n",
    "    classifier.add(Dense(units = 100, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "\n",
    "parameters = {'batch_size': [15,25],\n",
    "              'epochs': [100, 200],\n",
    "              'optimizer': ['rmsprop', 'adam']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_train)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy: \", accuracy_score(Y_train, y_pred))\n",
    "print(\"recall: \", recall_score(Y_train, y_pred))\n",
    "print(\"precision: \", precision_score(Y_train, y_pred))\n",
    "print(\"F-1 score: \", f1_score(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classifier.predict(X_test)\n",
    "y_pred_test = (y_pred_test > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy: \", accuracy_score(Y_train, y_pred_test))\n",
    "print(\"recall: \", recall_score(Y_train, y_pred_test))\n",
    "print(\"precision: \", precision_score(Y_train, y_pred_test))\n",
    "print(\"F-1 score: \", f1_score(Y_train, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
